{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Autor: Matyáš Sládek <br>\n",
    "Rok: 2020 <br>\n",
    "\n",
    "Tento soubor obsahuje funkce pro výpis výsledků selekce atributů, optimalizace parametrů či klasifikace."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tato buňka vypíše informace o optimalizaci parametrů. <br>\n",
    "V proměnné <code>datasets</code> je možné vybrat, pro které datové sady mají být informace vypasány. <br>\n",
    "V proměnné <code>feature_extraction_libraries</code> je možné vybrat, pro atributy které z extrakčních knihoven mají být informace vypasány. <br>\n",
    "V proměnné <code>feature_sets</code> je možné vybrat, pro které sady atributů mají být informace vypasány. <br>\n",
    "V proměnné <code>classifiers</code> je možné vybrat, pro které klasifikátory mají být informace vypasány. <br>\n",
    "V proměnné <code>validation_types</code> je možné vybrat, pro které typy validací (u optimalizace) mají být informace vypasány. <br>\n",
    "Nastavením proměnné <code>show_all_trials</code> na hodnotu True je možné vysat informace o každé iteraci optimalizace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "from datetime import timedelta\n",
    "import optuna\n",
    "import copy\n",
    "\n",
    "def get_duration(elem):\n",
    "    return(elem.datetime_complete - elem.datetime_start)\n",
    "\n",
    "datasets = [\n",
    "#     'EBD',\n",
    "#     'FMA',\n",
    "    'GTZAN'\n",
    "]\n",
    "\n",
    "feature_extraction_libraries = [\n",
    "#     'librosa',\n",
    "    'essentia'\n",
    "]\n",
    "\n",
    "feature_sets = [\n",
    "    'all',\n",
    "#     'opt_feature_set_FS_VS',\n",
    "#     'opt_feature_set_BE_VS'\n",
    "]\n",
    "\n",
    "classifiers = [\n",
    "        # sklearn classifiers\n",
    "#         'LogisticRegression',\n",
    "        'KNeighborsClassifier',\n",
    "#         'MLPClassifier',\n",
    "#         'DecisionTreeClassifier',\n",
    "#         'SVC_linear',\n",
    "#         'SVC_rbf',\n",
    "        \n",
    "        # sklearn ensemble classifiers\n",
    "#         'RandomForestClassifier',\n",
    "        \n",
    "        # other classifiers\n",
    "#         'XGBClassifier'\n",
    "]\n",
    "\n",
    "validation_types = [\n",
    "    'VS',\n",
    "    'CV'\n",
    "]\n",
    "\n",
    "show_all_trials = False\n",
    "\n",
    "for dataset in datasets:\n",
    "    print('#'*100)\n",
    "    print('Results for dataset \\033[1m{}\\033[0m:'.format(dataset))\n",
    "    \n",
    "    for library in feature_extraction_libraries:\n",
    "        print('*'*100)\n",
    "        print('Results for library \\033[1m{}\\033[0m:'.format(library))\n",
    "        for feature_set in feature_sets:\n",
    "            print('-'*100)\n",
    "            print('Results for feature_set \\033[1m{}\\033[0m:'.format(feature_set))\n",
    "            for classifier in classifiers:\n",
    "                for validation_type in validation_types:\n",
    "                    study = joblib.load('../metadata/optuna_studies/{}_{}_{}_{}_{}.pkl'.format(dataset, library, feature_set, classifier, validation_type)) \n",
    "                    print('')\n",
    "\n",
    "                    if show_all_trials:\n",
    "                        for trial in study.trials:\n",
    "                            if trial.state == optuna.trial.TrialState.COMPLETE:\n",
    "                                print('{} {} {} {} {}'.format(trial.number, trial.state, trial.value, str(trial.datetime_complete - trial.datetime_start).split('.')[0], trial.user_attrs['params']))\n",
    "                            else:\n",
    "                                print('{} {}'.format(trial.number, trial.state))\n",
    "\n",
    "                    print('\\nOptimisation info about classifier \\033[1m{}\\033[0m with validation type \\033[1m{}\\033[0m:'.format(classifier, validation_type))\n",
    "                    print('Total optimisation runtime: \\033[1m{}\\033[0m\\n'.format(str(study.trials[len(study.trials)-1].datetime_complete - study.trials[0].datetime_start).split('.')[0]))\n",
    "                    print('Best trial:\\n\\tNumber:   \\033[1m{}\\033[0m\\n\\tScore:    \\033[1m{}\\033[0m\\n\\tRuntime:  \\033[1m{}\\033[0m\\n\\tParams:   \\033[1m{}\\033[0m'.format(study.best_trial.number, study.best_trial.value, str(study.best_trial.datetime_complete - study.best_trial.datetime_start).split('.')[0], study.best_trial.user_attrs['params']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tato buňka vypíše informace o selekci atributů. <br>\n",
    "V proměnné <code>datasets</code> je možné vybrat, pro které datové sady mají být informace vypasány. <br>\n",
    "V proměnné <code>feature_extraction_libraries</code> je možné vybrat, pro atributy které z extrakčních knihoven mají být informace vypasány. <br>\n",
    "V proměnné <code>feature_sets</code> je možné vybrat, pro které sady atributů mají být informace vypasány. <br>\n",
    "V proměnné <code>classifiers</code> je možné vybrat, pro které klasifikátory mají být informace vypasány. <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import json\n",
    "\n",
    "try:\n",
    "    with open('../metadata/misc/optimised_feature_sets.json') as f:\n",
    "        optimised_feature_sets = json.load(f)   \n",
    "except Exception as e:\n",
    "    print('Failed to read file: \"../metadata/misc/optimised_feature_sets.json\"!', file=sys.stderr)\n",
    "    print('Error: {}'.format(repr(e)), file=sys.stderr)\n",
    "    \n",
    "datasets = [\n",
    "    'EBD',\n",
    "#     'FMA',\n",
    "#     'GTZAN'\n",
    "]\n",
    "\n",
    "feature_extraction_libraries = [\n",
    "#     'librosa',\n",
    "    'essentia'\n",
    "]\n",
    "\n",
    "feature_sets = [\n",
    "    'opt_feature_set_FS_VS',\n",
    "    'opt_feature_set_BE_VS'\n",
    "]\n",
    "\n",
    "classifiers = [\n",
    "        # sklearn classifiers\n",
    "#         'LogisticRegression',\n",
    "        'KNeighborsClassifier',\n",
    "#         'MLPClassifier',\n",
    "#         'DecisionTreeClassifier',\n",
    "#         'SVC_linear',\n",
    "#         'SVC_rbf',\n",
    "        \n",
    "        # sklearn ensemble classifiers\n",
    "#         'RandomForestClassifier',\n",
    "        \n",
    "        # other classifiers\n",
    "#         'XGBClassifier'\n",
    "]\n",
    "\n",
    "for dataset in datasets:\n",
    "    print('#'*100)\n",
    "    print('Results for dataset \\033[1m{}\\033[0m:'.format(dataset))\n",
    "    \n",
    "    for library in feature_extraction_libraries:\n",
    "        print('*'*100)\n",
    "        print('Results for library \\033[1m{}\\033[0m:'.format(library))\n",
    "        for feature_set_name in feature_sets:\n",
    "            print('-'*100)\n",
    "            print('Results for feature_set \\033[1m{}\\033[0m:'.format(feature_set_name))\n",
    "            for classifier in classifiers:\n",
    "                feature_set = optimised_feature_sets[dataset][library][classifier][feature_set_name]\n",
    "                print('Feature subset info for classifier \\033[1m{}\\033[0m:'.format(classifier))\n",
    "                print('Features selected: \\033[1m{}\\033[0m'.format(len(feature_set)))\n",
    "                print('Features: \\033[1m{}\\033[0m'.format(feature_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tato buňka vypíše informace o dosaženém skóre a době trénování a klasifikace pro vybrané klasifikační algoritmy sady atributů. <br>\n",
    "V proměnné <code>datasets</code> je možné vybrat, pro které datové sady mají být informace vypasány. <br>\n",
    "V proměnné <code>feature_extraction_libraries</code> je možné vybrat, pro atributy které z extrakčních knihoven mají být informace vypasány. <br>\n",
    "V proměnné <code>feature_sets</code> je možné vybrat, pro které sady atributů mají být informace vypasány. <br>\n",
    "V proměnné <code>control_sets</code> je možné vybrat, pro které testovací/validační sady mají být informace vypasány. <br>\n",
    "Nastavením proměnné <code>load_f1_score</code> na hodnotu True je možné načíst hodnoty F1 skóre, při hodnotě False se vypíše klasické skóre (počet správně / počet celkem) <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython.display as ipd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "       \n",
    "    def highlight_max(s):\n",
    "        is_max = s == s.max()\n",
    "        return ['background-color: yellow' if v else '' for v in is_max]\n",
    "        \n",
    "    datasets = [\n",
    "        'EBD',\n",
    "        'FMA',\n",
    "        'GTZAN'\n",
    "    ]\n",
    "    \n",
    "    feature_extraction_libraries = [\n",
    "#         'librosa',\n",
    "        'essentia'\n",
    "    ]\n",
    "    \n",
    "    feature_sets = [\n",
    "        'all',\n",
    "        'opt_feature_set_FS_VS',\n",
    "        'opt_feature_set_BE_VS'\n",
    "    ]\n",
    "    \n",
    "    control_sets = [\n",
    "#         'validation_set',\n",
    "        'test_set'\n",
    "    ]\n",
    "    \n",
    "    load_f1_score = False\n",
    "\n",
    "    scs = pd.DataFrame()\n",
    "    rts = pd.DataFrame()\n",
    "    \n",
    "    for dataset in datasets:\n",
    "        for library in feature_extraction_libraries:\n",
    "            for control_set in control_sets:\n",
    "                \n",
    "                scores = pd.read_csv(\"../metadata/scores/scores_{}_{}_{}_{}.csv\".format(dataset, library, control_set, 'F1_score' if load_f1_score else 'accuracy_score'), index_col=0, header=[0])\n",
    "                scs = scs.append(scores)\n",
    "                runtimes = pd.read_csv(\"../metadata/runtimes/runtimes_{}_{}_{}.csv\".format(dataset, library, control_set), index_col=0, header=[0])\n",
    "                rts = rts.append(runtimes)\n",
    "\n",
    "#     cols = [c for c in scs.columns if 'default' not in c]\n",
    "#     cols = [c for c in cols if 'VS' not in c]\n",
    "#     scs = scs[cols]\n",
    "#     rts = rts[cols]\n",
    "     \n",
    "    index = scs.index.unique()\n",
    "    index = pd.MultiIndex.from_product([['EBD', 'FMA', 'GTZAN'], list(index)])\n",
    "    scs = scs.reset_index(drop=True)\n",
    "    scs = pd.DataFrame(data=scs.values, index=index, columns=scs.columns.str.replace('_default',''))\n",
    "    indices_to_drop = [x for x in ['all', 'opt_feature_set_FS_VS', 'opt_feature_set_BE_VS'] if x not in feature_sets]\n",
    "    if len(indices_to_drop) != 0:\n",
    "        scs = scs.drop(indices_to_drop, level=1)\n",
    "    scs.to_csv('../../bp/classification_scores.csv')  \n",
    "    scs = scs.style.apply(highlight_max, axis=1)\n",
    "    ipd.display(scs.format(\"{:.2%}\"))\n",
    "\n",
    "    index = rts.index.unique()\n",
    "    index = pd.MultiIndex.from_product([['EBD', 'FMA', 'GTZAN'], list(index)])\n",
    "    rts = rts.reset_index(drop=True)\n",
    "    rts = pd.DataFrame(data=rts.values, index=index, columns=rts.columns.str.replace('_default',''))\n",
    "    if len(indices_to_drop) != 0:\n",
    "        rts = rts.drop(indices_to_drop, level=1)\n",
    "    rts.to_csv('../../bp/classification_runtimes.csv')  \n",
    "    ipd.display(rts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
