{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Autor: Matyáš Sládek <br>\n",
    "Rok: 2020 <br>\n",
    "\n",
    "Tento soubor slouží k extrakci atributů ze skladeb datových sad či lokálního hudebního archivu. <br>\n",
    "Postupujte podle návodů u jednotlivých buňěk <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tato buňka importuje potřebné knihovny."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "import multiprocessing as mp\n",
    "import time\n",
    "from datetime import timedelta\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import soundfile as sf\n",
    "\n",
    "import librosa\n",
    "import essentia.standard as es\n",
    "\n",
    "from tqdm.notebook import tqdm   # Progress bars\n",
    "tqdm().pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tato buňka obsahuje funkci pro tisk na obrazovku a zároveň do souboru <strong>feature_extraction.out</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_log(*args, **kwargs):\n",
    "    \"\"\"\n",
    "    Prints to stdout and logs to file.\n",
    "    \"\"\"\n",
    "    print(*args, **kwargs)   # Print to stdout\n",
    "    with open('../metadata/misc/feature_extraction.out','a') as file:\n",
    "        print(re.sub('\\\\033\\[.m', '', *args), file=file)   # Print to log file with removed bold text, that would not display correctly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tato buňka extrahuje atributy pomocí funkcí knihovny <strong>Librosa</strong>. <br>\n",
    "Zde je možné upravit parametry extrakčních funkcí či nějaké extrakční funkce přidat či odstranit. <br>\n",
    "Délka okna pro převod signálu do frekvenční oblasti metodami Short-time Fourier transform a Constant-Q transform je nastavena na hodnotu 2048 vzorků a posun oken na hodnotu 1024 vzorků. <br>\n",
    "Každá skladba je načtena se vzorkovací frekvencí 44100 Hz, skladby s jinou vzorkovací frekvencí jsou případně převzorkovány, aby nebylo nutné upavovat parametry extrakčních funkcí. <br>\n",
    "Detailní popis parametrů a funkcí této knihovny je možné nalézt zde <https://librosa.org/doc/latest/index.html>  a některých, včetně vizualizace zde <https://musicinformationretrieval.com/>. <br>\n",
    "Celkem je extrahováno 14 atributů, a to: <br>\n",
    "<ul>\n",
    "    <li><strong>zero_crossing_rate</strong> - Počet průchodů signálu nulovou úrovní (změna znaménka u amplitudy)</li>\n",
    "    <li><strong>chroma_cens</strong> - Normalizované statistiky energií tónů chromatické stupnice</li>\n",
    "    <li><strong>chroma_cqt</strong> - Constant-Q spektrogram s pásmy chromatické stupnice</li>\n",
    "    <li><strong>tonnetz</strong> - Intonace not</li>\n",
    "    <li><strong>rms</strong> - Energie signálu</li>\n",
    "    <li><strong>spectral_centroid</strong> - Geometrický střed frekvenčního spektra</li>\n",
    "    <li><strong>spectral_bandwidth</strong> - Šířka distribuce frekvencí</li>\n",
    "    <li><strong>spectral_contrast</strong> - Rozdíl energie vrcholů a údolí spektra</li>\n",
    "    <li><strong>spectral_flatness</strong> - Drsnost frekvenčního spektra (je signál více jako tón či hluk)</li>\n",
    "    <li><strong>spectral_rolloff</strong> - Frekvence, pod kterou spadá 85 % energie spektra</li>\n",
    "    <li><strong>stft</strong> - Spektrogram</li>\n",
    "    <li><strong>mel_spectrogram</strong> - Spektrogram s frekvenční osou převedenou do Mel-frekvenční škály</li>\n",
    "    <li><strong>mfcc</strong> - Mel-frekvenční kepstrální koeficienty</li>\n",
    "    <li><strong>tempo</strong> - Tempo</li>\n",
    "</ul>\n",
    "\n",
    "Všechy extrahované atributy jsou ve formátu: <br>\n",
    "[název_atributu] [statistická_funkce] [číslo_hodnoty] [hodnota_atributu] <br>\n",
    "Skladba je identifikována cestou k souboru jeho názvem uloženém v názvu objektu Pandas Series. <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features_librosa(filepath):\n",
    "    \"\"\"\n",
    "    Extracts features using Librosa library.\n",
    "\n",
    "    Parameters:\n",
    "\n",
    "    filepath: path to the audio file\n",
    "    \"\"\"\n",
    "    def process_feature(feature_name):\n",
    "        \"\"\"\n",
    "        Transforms extracted feature into indexed format used to create pandas series. Statistic functions are used to reduce dimensionality when needed.\n",
    "        \n",
    "        Parameters:\n",
    "        \n",
    "        feature_name: name of the feature\n",
    "        \"\"\"\n",
    "        if feature.size > 1:   # If a feature is a list or list of lists, process it with statistic functions to reduce dimensionality\n",
    "            \n",
    "            # For each statistic function, process the feature with it and create frst two rows of multiindex\n",
    "            for statistic_name, statistic in statistics.items():\n",
    "                processed_feature = statistic(feature, axis=1)\n",
    "                index = [feature_name, statistic_name]\n",
    "\n",
    "                if isinstance(processed_feature, (np.ndarray)):   # If processed feature has multiple values\n",
    "                    \n",
    "                    # For each value of the feature, append unique number to multiindex\n",
    "                    for i, processed_feature_i in enumerate(processed_feature):\n",
    "                        index.append('{:03d}'.format(i+1))\n",
    "\n",
    "                        # Append multiindex to indices list\n",
    "                        for j in range(3):\n",
    "                            indices[j].append(index[j])\n",
    "\n",
    "                        data.append('{:.7e}'.format(processed_feature_i))   # Append processed feature values to data list\n",
    "                        index = index[:-1]   # Reset last row of multiindex\n",
    "                else:   #If processed feature has one value\n",
    "                    index.append('001')   # Append unique value to multiindex\n",
    "\n",
    "                    # Append multiindex to indices list\n",
    "                    for j in range(3):\n",
    "                        indices[j].append(index[j]) \n",
    "\n",
    "                    data.append('{:.7e}'.format(processed_feature))   # Append processed feature values to data list                    \n",
    "        else:   # If feature is a single value, do not process it with statistic functions\n",
    "            index = [feature_name, 'none', '001']   # Create multiindex\n",
    "            \n",
    "            # Append multiindex to indices list\n",
    "            for j in range(3):\n",
    "                indices[j].append(index[j])\n",
    "\n",
    "            data.append('{:.7e}'.format(feature[0]))   # Append processed feature values to data list\n",
    "\n",
    "        return \n",
    "        \n",
    "    # Statistic functions to be used, unwanted can be commented out   \n",
    "    statistics = {\n",
    "        'mean':np.mean,\n",
    "        'std':np.std,\n",
    "        'median':np.median,\n",
    "        'min':np.min,\n",
    "        'max':np.max,\n",
    "        'skew':stats.skew,\n",
    "        'kurtosis':stats.kurtosis,\n",
    "    }      \n",
    "    data = []   # Stores feature values\n",
    "    indices = [[], [], []]   # Stores indices of feature values for pandas series\n",
    "    names = ['feature', 'statistic', 'number']   # Names of indices\n",
    "\n",
    "    # Load track \n",
    "    try:\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter(\"ignore\")\n",
    "            y, sr = librosa.load(filepath, sr=44100, mono=True)\n",
    "    except Exception as e:\n",
    "        print_log('Loading file: \"{}\" with Librosa library has failed! Error: {}'.format(filepath, repr(e)), file=sys.stderr)\n",
    "        return\n",
    "                \n",
    "    duration = librosa.get_duration(y=y, sr=sr)   # Get track duration\n",
    "\n",
    "    ###################################################################################################################################################\n",
    "    \n",
    "    # Quality control of datasets, comment out if using full length tracks\n",
    "    \n",
    "    # Remove tracks with wrong duration (should be 30 s)\n",
    "    if not ((duration > 29) and (duration < 31)):\n",
    "        print_log(\"Track \" + filepath + \" does not have an approximate duration of 30 s. Its duration is \" + str(duration) + \" seconds.\", file=sys.stderr)\n",
    "        return\n",
    "    \n",
    "    ###################################################################################################################################################\n",
    "\n",
    "    frame_length = 2048   # Length of a window for frequency analysis corresponds to 46 ms of audio which should be sufficient\n",
    "    # higher value may be better for more accurate frequency analysis of tonal features, but that is already used in Essentia library, so this value is left for comparison\n",
    "    hop_length = 1024   # Length of step between windows, set to half of frame length so each frame is fully overlaped by adjacent windows\n",
    "\n",
    "    # Extract zero crossing rate feature (rate of change in amplitude sign)\n",
    "    feature = librosa.feature.zero_crossing_rate(y, frame_length=frame_length, hop_length=hop_length)\n",
    "    process_feature('zero_crossing_rate')\n",
    "\n",
    "    # Compute constant-Q transform (similiar to STFT, adjusts band size to logarithmic to reflect human hearing) 7 octaves of 12 bins used (default)\n",
    "    # Hanning window function to smooth out signal at frame borders\n",
    "    C = np.abs(librosa.cqt(y, sr=sr, hop_length=hop_length, n_bins=84, bins_per_octave=12, tuning=None, window='hann', scale=True))\n",
    "\n",
    "    # Extract chroma cens feature, 7 octaves with 12 notes each to reflect chromatic scale (used for note/melody detection)\n",
    "    feature = librosa.feature.chroma_cens(C=C, n_chroma=12, n_octaves=7)\n",
    "    process_feature('chroma_cens')\n",
    "\n",
    "    # Extract chroma cqt feature, 7 octaves with 12 notes each to reflect chromatic scale (used for note/melody detection)\n",
    "    feature = librosa.feature.chroma_cqt(C=C, n_chroma=12, n_octaves=7)\n",
    "    process_feature('chroma_cqt')\n",
    "\n",
    "    # Extract tonnetz feature, used to detect intonation\n",
    "    feature = librosa.feature.tonnetz(chroma=feature)\n",
    "    process_feature('tonnetz')   \n",
    "\n",
    "    # Compute short-time Fourier transform\n",
    "    # Hanning window function to smooth out signal at frame borders\n",
    "    S = np.abs(librosa.stft(y, n_fft=frame_length, hop_length=hop_length, window='hann'))\n",
    "\n",
    "    # Extract root mean square feature (signal energy)\n",
    "    feature = librosa.feature.rms(S=S)\n",
    "    process_feature('rms')\n",
    "\n",
    "    # Extract spectral centroid feature (geometrical center of frequency distribution)\n",
    "    feature = librosa.feature.spectral_centroid(S=S)\n",
    "    process_feature('spectral_centroid')\n",
    "\n",
    "    # Extract spectral bandwidth feature (measures spread of distribution of frequencies)\n",
    "    feature = librosa.feature.spectral_bandwidth(S=S)\n",
    "    process_feature('spectral_bandwidth')\n",
    "\n",
    "    # Extract spectral contrast feature (energy difference between crests and troughs)\n",
    "    feature = librosa.feature.spectral_contrast(S=S, sr=sr)\n",
    "    process_feature('spectral_contrast')\n",
    "\n",
    "    # Extract spectral flatness feature (measures noisiness of signal)\n",
    "    feature = librosa.feature.spectral_flatness(S=S)\n",
    "    process_feature('spectral_flatness')\n",
    "\n",
    "    # Extract spectral rolloff feature (measures frequency under which 85 % of the spectral energy lies)\n",
    "    feature = librosa.feature.spectral_rolloff(S=S, sr=sr, roll_percent=0.85)\n",
    "    process_feature('spectral_rolloff')\n",
    "\n",
    "    # Transform magnitude spectrogram to power spectrogram\n",
    "    S = S**2\n",
    "\n",
    "    # Extract chroma short time Fourier transform (similiar to chroma_CQT, but has constant frequency band size)\n",
    "    feature = librosa.feature.chroma_stft(S=S, sr=sr, tuning=None, n_chroma=12)\n",
    "    process_feature('chroma_stft')\n",
    "\n",
    "    # Extract mel-spectrogram (spectrogram in mel-frequencz scale to reflect human hearing, linear to 1 kHz than logarithmic)\n",
    "    feature = librosa.feature.melspectrogram(S=S, sr=sr, n_mels=128)\n",
    "    process_feature('melspectrogram')\n",
    "\n",
    "    # Extract mel-frequency cepstral coefficients (compact form of mel-spectrogram)\n",
    "    feature = librosa.feature.mfcc(S=librosa.power_to_db(feature), n_mfcc=20, dct_type=2, norm='ortho')\n",
    "    process_feature('mfcc')\n",
    "\n",
    "    # Compute onset strength envelope (used to detect sudden changes in amplitude)\n",
    "    onset_env = librosa.onset.onset_strength(y, sr=sr)\n",
    "\n",
    "    # Extract estimated tempo\n",
    "    feature = librosa.beat.tempo(onset_envelope=onset_env, sr=sr)\n",
    "    process_feature('tempo')\n",
    "\n",
    "    features = pd.Series(data=data, index=pd.MultiIndex.from_arrays(indices, names=names))   # Transform processed features to pandas series\n",
    "    features.name = filepath   # Create index for the series of features\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tato buňka extrahuje atributy pomocí funkcí knihovny <strong>Essentia</strong>. <br>\n",
    "Zde je možné upravit parametry extrakční funkce. <br>\n",
    "\n",
    "Hodnoty parametrů extrakční funkce: <br>\n",
    "<ul>\n",
    "    <li><strong>'analysisSampleRate': 44100</strong> - Vzorkovací frekvence skladeb pro analýzu, 44100 Hz (CD kvalita), skladby jsou případně převzorkovány.</li>\n",
    "    <li><strong>'endTime': 1e+06</strong> - Jak dlouhý úsek skladby má být analyzován, nastaveno na celou skladbu.</li>\n",
    "    <li><strong>'gfccStats': [\"mean\", \"cov\", \"icov\"]</strong> - Jaké statistické funkce použít pro zpracování hodnot gamma tónových kepstrálních koeficientů, nastaveno na průměr, kovarianci a inverzní kovarianci.</li>\n",
    "    <li><strong>'loudnessFrameSize': 88200</strong> - Délka okna pro časově-frekvenční analýzu pro odhad hlasitosti, nastaveno na hodnotu 88200 vzorků, což odpovídá úseku dlouhému 2 sekundy. Delší okno je vhodné pro přesnější odhad.</li>\n",
    "    <li><strong>'loudnessHopSize': 44100</strong> - Posun  okna pro časově-frekvenční analýzu pro odhad hlasitosti, nastaveno na délku poloviny okna, takže se každé okno z poloviny překrývá z oknem předchozím.</li>\n",
    "    <li><strong>'lowlevelFrameSize': 2048</strong> - Délka okna pro časově-frekvenční analýzu pro výpočet nízko-úrovňových atributů, nastaveno na hodnotu 2048 vzorků, což odpovídá úseku dlouhému 46 milisekund. Kratší okno je vhodné pro přesnější časovou analýzu.</li>\n",
    "    <li><strong>'lowlevelHopSize': 1024</strong> - Posun okna pro časově-frekvenční analýzu pro výpočet nízko-úrovňových atributů, nastaveno na délku poloviny okna, takže se každé okno z poloviny překrývá z oknem předchozím.</li>\n",
    "    <li><strong>'lowlevelSilentFrames': 'noise'</strong> - Zpracování oken neobsahujících zvuk, ponechána výchozí hodnota 'noise' - doplnění šumem.</li>\n",
    "    <li><strong>'lowlevelStats': [\"mean\", \"var\", \"stdev\", \"median\", \"min\", \"max\", \"dmean\", \"dmean2\", \"dvar\", \"dvar2\"]</strong> - Jaké statistické funkce použít pro zpracování hodnot nízkoúrovňových atributů, nastaveno na průměr, rozptyl, směrodatnou odchylku, medián, minimální hodnotu, maximální hodnotu, průměr první derivace, průměr druhé derivace, rozptyl první derivace a rozptyl druhé derivace.</li>\n",
    "    <li><strong>'lowlevelWindowType': 'blackmanharris62'</strong> - Typ okénkové funkce pro zpracování oken spektrogramu pro nízkoúrovňové atributy. Nastaveno typ blackmanharris62.</li>\n",
    "    <li><strong>'lowlevelZeroPadding': 0</strong> - Odsazení oken pro nízkoúrovňové atributy, nepoužito.</li>\n",
    "    <li><strong>'mfccStats': [\"mean\", \"cov\", \"icov\"]</strong> - Jaké statistické funkce použít pro zpracování hodnot Mel-frekvenčních kepstrálních koeficientů, nastaveno na průměr, kovarianci a inverzní kovarianci.</li>\n",
    "    <li><strong>'profile': ''</strong> - Profil pro načtení parametrů, nepoužito.</li>\n",
    "    <li><strong>'requireMbid': False</strong> - Vyžadovat tag MusicBrainz databáze, nepoužito.</li>\n",
    "    <li><strong>'rhythmMaxTempo': 208</strong> - Maximální hodnota tempa, nastaveno na hodnotu 208 úderů za minutu, což by mělo zamezit odhadům tempa ze čtvrtdob a podobně.</li>\n",
    "    <li><strong>'rhythmMethod': 'degara'</strong> - Metoda pro odhad tempa, nastaveno na metodu degara.</li>\n",
    "    <li><strong>'rhythmMinTempo': 40</strong> - Minimální hodnota tempa, nastaveno na hodnotu 40 úderů za minutu.</li>\n",
    "    <li><strong>'rhythmStats': [\"mean\", \"var\", \"stdev\", \"median\", \"min\", \"max\", \"dmean\", \"dmean2\", \"dvar\", \"dvar2\"]</strong> - Jaké statistické funkce použít pro zpracování hodnot rytmických atributů, nastaveno na průměr, rozptyl, směrodatnou odchylku, medián, minimální hodnotu, maximální hodnotu, průměr první derivace, průměr druhé derivace, rozptyl první derivace a rozptyl druhé derivace.</li>\n",
    "    <li><strong>'startTime': 0</strong> - Od jakého času začít analýzu, nastaveno na hodnotu 0 sekund.</li>\n",
    "    <li><strong>'tonalFrameSize': 4096</strong> - Délka okna pro časově-frekvenční analýzu pro výpočet melodických atributů, nastaveno na hodnotu 4096 vzorků, což odpovídá úseku dlouhému 92 milisekund. Delší okno je vhodné pro přesnější frekvenční odhad.</li>\n",
    "    <li><strong>'tonalHopSize': 2048</strong> - Posun okna pro časově-frekvenční analýzu pro výpočet melodických atributů, nastaveno na délku poloviny okna, takže se každé okno z poloviny překrývá z oknem předchozím.</li>\n",
    "    <li><strong>'tonalSilentFrames': 'noise'</strong> - Zpracování oken neobsahujících zvuk, ponechána výchozí hodnota 'noise' - doplnění šumem.</li>\n",
    "    <li><strong>'tonalStats': [\"mean\", \"var\", \"stdev\", \"median\", \"min\", \"max\", \"dmean\", \"dmean2\", \"dvar\", \"dvar2\"]</strong> - Jaké statistické funkce použít pro zpracování hodnot melodických atributů, nastaveno na průměr, rozptyl, směrodatnou odchylku, medián, minimální hodnotu, maximální hodnotu, průměr první derivace, průměr druhé derivace, rozptyl první derivace a rozptyl druhé derivace.</li>\n",
    "    <li><strong>'tonalWindowType': 'blackmanharris62'</strong> - Typ okénkové funkce pro zpracování oken spektrogramu pro melodické atributy. Nastaveno typ blackmanharris62.</li>\n",
    "    <li><strong>'tonalZeroPadding': 0</strong> - Odsazení oken pro melodické atributy, nepoužito.</li>\n",
    "</ul>\n",
    "\n",
    "Každá skladba je načtena se vzorkovací frekvencí 44100 Hz, skladby s jinou vzorkovací frekvencí jsou případně převzorkovány, aby nebylo nutné upavovat parametry extrakčních funkcí. <br>\n",
    "Detailní popis extrakční funkce, parametrů a atributů této knihovny je možné nalézt zde <https://essentia.upf.edu/reference/std_MusicExtractor.html> <br>\n",
    "Celkem je extrahováno 80 atributů, z toho 49 nízkoúrovňových, 14 rytmických a 17 melodických/harmonických. <br>\n",
    "Všechy extrahované atributy jsou ve formátu: <br>\n",
    "[úroveň_atributu][název_atributu] [statistická_funkce] [číslo_hodnoty] [hodnota_atributu] <br>\n",
    "Skladba je identifikována cestou k souboru jeho názvem uloženém v názvu objektu Pandas Series. <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features_essentia(filepath):\n",
    "    \"\"\"\n",
    "    Extracts features using Essentia library.\n",
    "\n",
    "    Parameters:\n",
    "\n",
    "    filepath: path to the audio file\n",
    "    \"\"\"\n",
    "    # Parameters used by Essentia music extractor (see Essentia docs)\n",
    "    params = {\n",
    "        'analysisSampleRate': 44100,   # Sample rate for the analysis, tracks are resampled if necessary\n",
    "        'endTime': 1e+06,   # How much of the track should be loaded, set to high number to fully load tracks (each has 30s)\n",
    "        'gfccStats': [\"mean\", \"cov\", \"icov\"],   # Which statistc functions to use for dimensionality reduction of gammatone frequency cepstral coefficients, mean, covariance and inverse covariance are used \n",
    "        'loudnessFrameSize': 88200,   # Frame size of STFT window for estimating loudness, higher number is needed for more accurate estimation (corresponds to 2 sec of audio)\n",
    "        'loudnessHopSize': 44100,   # Hop size is set to half the frame size so that each frame is fully covered by adjacent frames to avoid incorrect estimations on window borders\n",
    "        'lowlevelFrameSize': 2048,   # Frame size of STFT window for extraction of low level features, set to lower value to have more time accurate analysis (corresponds to 46 miliseconds of audio)\n",
    "        'lowlevelHopSize': 1024,   # Hop size is set to half the frame size so that each frame is fully covered by adjacent frames to avoid incorrect estimations on window borders\n",
    "        'lowlevelSilentFrames': 'noise',   # Replaces frames that only contain silence to random noise\n",
    "        'lowlevelStats': [\"mean\", \"var\", \"stdev\", \"median\", \"min\", \"max\", \"dmean\", \"dmean2\", \"dvar\", \"dvar2\"],   # Statistic functions for processing low level features\n",
    "                        # mean, variance, standard deviation, median, minimum, maximum, mean and variance of first and second derivatives\n",
    "        'lowlevelWindowType': 'blackmanharris62',   # Windowing function to smooth out frame borders for frequency analysis\n",
    "        'lowlevelZeroPadding': 0,   # Not used (padding windows with zeroes)\n",
    "        'mfccStats': [\"mean\", \"cov\", \"icov\"],   # Which statistc functions to use for dimensionality reduction of mel-frequency cepstral coefficients, mean, covariance and inverse covariance are used \n",
    "        'profile': '',   # Not used (for overwritting parameter values)\n",
    "        'requireMbid': False,   # Not used (ignores tracks without MusicBrainz tags)\n",
    "        'rhythmMaxTempo': 208,   # Mamium value for tempo estimation to reduce detecting half/quarter beats (multiples of actual tempo)\n",
    "        'rhythmMethod': 'degara',   # Method for tempo estimation\n",
    "        'rhythmMinTempo': 40,   # Minimum value for tempo detection to avoid detecting fractions of actual tempo\n",
    "        'rhythmStats': [\"mean\", \"var\", \"stdev\", \"median\", \"min\", \"max\", \"dmean\", \"dmean2\", \"dvar\", \"dvar2\"],   # Same as low level\n",
    "        'startTime': 0,   # Start time of analysis se to start of track\n",
    "        'tonalFrameSize': 4096,   # Frame size of STFT window for extraction of tonal features, set to higher value to have more frequency accurate analysis for note detection (corresponds to 92 miliseconds of audio)\n",
    "        'tonalHopSize': 2048,   # Hop size is set to half the frame size so that each frame is fully covered by adjacent frames to avoid incorrect estimations on window borders\n",
    "        'tonalSilentFrames': 'noise',   # Same as low level\n",
    "        'tonalStats': [\"mean\", \"var\", \"stdev\", \"median\", \"min\", \"max\", \"dmean\", \"dmean2\", \"dvar\", \"dvar2\"],   # Same as low level\n",
    "        'tonalWindowType': 'blackmanharris62',   # Same as low level\n",
    "        'tonalZeroPadding': 0,   # Same as low level\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        # If a file is in .au format, create temporary .wav file from it file to be processed with Essentia music extractor (.au is not supported)\n",
    "        # Then extract features\n",
    "        if filepath.lower().endswith('.au'):\n",
    "            data, samplerate = sf.read(filepath)\n",
    "            tmp_filepath = os.path.join('../data/tmp', '{}.wav'.format(os.path.splitext(os.path.basename(filepath))[0]))\n",
    "            sf.write(tmp_filepath, data, samplerate)\n",
    "            results, _ = es.MusicExtractor(**params)(tmp_filepath)\n",
    "            os.remove(tmp_filepath)\n",
    "        else:\n",
    "            results, _ = es.MusicExtractor(**params)(filepath)\n",
    "    except Exception as e:\n",
    "        print_log('Extracting features from file: \"{}\" with Essentia library has failed! Error: {}'.format(filepath, repr(e)), file=sys.stderr)\n",
    "        return\n",
    "\n",
    "    data = []   # Stores feature values\n",
    "    indices = [[], [], [], []]   # Stores indices of feature values for pandas series\n",
    "    names = ['category', 'feature', 'statistic', 'number']   # Names of indices\n",
    "\n",
    "    duration = results['metadata.audio_properties.length'] # Get track duration\n",
    "\n",
    "    ###################################################################################################################################################\n",
    "    \n",
    "    # Quality control of datasets, comment this out if using full length tracks\n",
    "    \n",
    "    # Remove tracks with wrong duration (should be 30 s)\n",
    "    if not ((duration > 29) and (duration < 31)):\n",
    "        print_log(\"Track \" + filepath + \" does not have an approximate duration of 30 s. Its duration is \" + str(duration) + \" seconds.\", file=sys.stderr)\n",
    "        return\n",
    "    \n",
    "    ###################################################################################################################################################\n",
    "\n",
    "    # Transform extracted features to a format suitable for pandas series (statistic functions were already applied by the extractor)\n",
    "    # For each feature\n",
    "    for feature_name in results.descriptorNames():\n",
    "        it = feature_name.split('.')   # Split features description for creating multiindex. Format is: (level, feature_name_first_word, feature_name_second_word, statistics)\n",
    "        feature = results[feature_name]   # Get the values of the feature\n",
    "\n",
    "        # If entry is not metadata\n",
    "        if not 'metadata' in it:\n",
    "            \n",
    "            # If feature was not processed with statistics functions, apend 'none' for statistics multiindex row\n",
    "            if len(it) == 2:\n",
    "                it.append('none')\n",
    "\n",
    "            # If feature has two word name, concatenate them together to keep constant level depth of multiindex\n",
    "            if len(it) == 4:\n",
    "                it = [it[0], '{}_{}'.format(it[1], it[2]), it[3]]\n",
    "\n",
    "            if isinstance(feature, (np.ndarray)):   # If feature is an array (can be multidimensional)\n",
    "                for i, feature_i in enumerate(feature):   # For each value of array\n",
    "                    if isinstance(feature_i, (np.ndarray)):   # If value is an array\n",
    "                        \n",
    "                        # For each value of the feature, append unique number to multiindex\n",
    "                        for j, feature_i_j in enumerate(feature_i):\n",
    "                            it.append('{:03d}'.format(j+1+i*len(feature_i)))\n",
    "\n",
    "                            # Append multiindex to indices list\n",
    "                            for k in range(4):\n",
    "                                indices[k].append(it[k])\n",
    "\n",
    "                            data.append('{:.7e}'.format(feature_i_j) if isinstance(feature_i_j, (np.float32)) else feature_i_j)   # Append feature values to data list\n",
    "                            it = it[:-1]   # Reset last row of multiindex\n",
    "                    else:   # If value is a single value\n",
    "                        it.append('{:03d}'.format(i+1))   # Append unique number to multiindex\n",
    "\n",
    "                        # Append multiindex to indices list\n",
    "                        for j in range(4):\n",
    "                            indices[j].append(it[j])\n",
    "\n",
    "                        data.append('{:.7e}'.format(feature_i) if isinstance(feature_i, (np.float32)) else feature_i)   # Append feature values to data list\n",
    "                        it = it[:-1]   # Reset last row of multiindex\n",
    "            else:   # If feature is a single value\n",
    "                it.append('001')   # Append unique number to multiindex\n",
    "\n",
    "                # Append multiindex to indices list\n",
    "                for i in range(4):\n",
    "                    indices[i].append(it[i])\n",
    "\n",
    "                data.append('{:.7e}'.format(feature) if isinstance(feature, (float)) else feature)   # Append feature values to data list\n",
    "\n",
    "    features = pd.Series(data=data, index=pd.MultiIndex.from_arrays(indices, names=names))   # Transform processed feature to pandas series\n",
    "    features.name = filepath   # Create index for the series of features\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tato buňka slouží k vytvoření seznamu cest k souborům z datové sady či archivu a následnému spuštění extrakce pomocí vybrané knihovny. <br>\n",
    "Cestu ke složkám se skladbami u vlastní datové sady je možné vložit do proměnné <code>datasets</code> ve formátu <code>'název_datové_sady':'cesta_k_datům'</code> <br>\n",
    "Které extrakční knihovny mají být použity je možné zvolit v proměnné <code>feature_extraction_libraries</code> zakomentováním/odkomentováním příslužného záznamu. <br>\n",
    "Pro zachování konstantního počtu atributů je možné nastavit proměnnou <code>drop_beats_position_feature</code> na hodnotu True. To je vhodné pro případ, kdy by natrénované klasifikátory byly využity pro predikci dat z jiné datové sady. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    # Dictionary of names and paths to datasets to be processed, unwanted can be commented out   \n",
    "    datasets = {\n",
    "#         'EBD':'../data/EBD',\n",
    "#         'FMA':'../data/FMA/fma_small',\n",
    "#         'GTZAN':'../data/GTZAN',\n",
    "        'local_archive':'../data/local_archive'\n",
    "    }\n",
    "    \n",
    "    #Dictionary of library names and functions to be used to proccess datasets, unwanted can be commented out   \n",
    "    feature_extraction_libraries = {\n",
    "        'librosa':extract_features_librosa,\n",
    "        'essentia':extract_features_essentia,\n",
    "    }\n",
    "    \n",
    "    # Whether to drop beats_position feature of Essentia library\n",
    "    drop_beats_position_feature = False   # This feature has variable length, which may cause problems when using trained classifiers to predict data from different dataset\n",
    "\n",
    "    # Create folder for storing features\n",
    "    if not os.path.exists('../metadata/features'):\n",
    "        try:\n",
    "            os.mkdir('../metadata/features')\n",
    "        except Exception as e:\n",
    "            print_log('{}: {}'.format('os.mkdir(../metadata/features)', repr(e)), file=sys.stderr)\n",
    "\n",
    "    t_start = time.time()   # Store start time of extraction process\n",
    "    \n",
    "    for dataset_name, path_to_dataset in tqdm(datasets.items(), desc='Datasets extraction progress'):   # For each of the selected datasets\n",
    "        paths_to_tracks = {}   # Stores tracks indices and paths\n",
    "\n",
    "        # Walk through every file of a dataset, if it is a track, append its index and path to a dictionary\n",
    "        for dir_path, _, files in os.walk(path_to_dataset):\n",
    "            for file in files:\n",
    "                if file.lower().endswith(('.mp3', '.au')):\n",
    "                    paths_to_tracks.update({os.path.join(dir_path, file): file})\n",
    "\n",
    "        # Get number of CPU cores for multiprocessing\n",
    "        workers = 1 if os.cpu_count() is None else os.cpu_count()\n",
    "\n",
    "        for library_name, extractor in feature_extraction_libraries.items():   # For each selected extraction library\n",
    "            \n",
    "            # Create temporary folder for storing temporary converted track files (essentia does not support loading GTZANs ULAW format)\n",
    "            if not os.path.exists('../data/tmp'):\n",
    "                try:\n",
    "                    os.mkdir('../data/tmp')\n",
    "                except Exception as e:\n",
    "                    print_log('{}: {}'.format('os.mkdir(../data/tmp)', repr(e)), file=sys.stderr)\n",
    "\n",
    "            t = time.time()   # Store start time of extraction process for each library and dataset\n",
    "            pool = mp.Pool(processes=workers)   # Initialize multiprocessing pool\n",
    "            print('{} dataset extraction using {} library progress:\\n'.format(dataset_name, library_name))\n",
    "            \n",
    "            # Commence extraction process and store successful results\n",
    "            result = [x for x in list(tqdm(pool.imap_unordered(extractor, list(paths_to_tracks.keys())), total=len(paths_to_tracks))) if x is not None]\n",
    "            print_log('{} dataset extraction using {} library finished in {}.'.format(dataset_name, library_name, str(timedelta(seconds=(time.time() - t))).split(\".\")[0]))\n",
    "            pool.close()   # Close multiprocessing pool\n",
    "            pool.join()   # Join processes\n",
    "\n",
    "            # If ULAW format had to loaded with Essentia library, remove temporary folder for storing temporary converted track files\n",
    "            if os.path.exists('../data/tmp'):\n",
    "                try:\n",
    "                    os.rmdir('../data/tmp')\n",
    "                except Exception as e:\n",
    "                    print_log('{}: {}'.format('os.rmdir(../data/tmp)', repr(e)), file=sys.stderr)\n",
    "                    \n",
    "            # Get index of features\n",
    "            index = result[0].index\n",
    "            \n",
    "            # Get shortest index to avoid having sparse dataframe due to variable length of feature beats_position\n",
    "            for r in result:\n",
    "                if len(r.index) < len(index):\n",
    "                    index = r.index\n",
    "                    \n",
    "            # Use shortest feature to create dataframe columns, cut longer features to avoid NaN values\n",
    "            features = pd.DataFrame(index=paths_to_tracks.keys(), columns=index)\n",
    "            \n",
    "            # Drop beats_position feature with variable length to avoid having problems when predicting data from a different dataset with trained classifiers\n",
    "            if drop_beats_position_feature:\n",
    "                features = features.drop('beats_position', axis=1, level=1)\n",
    "\n",
    "            # Populate dataframe with feature values\n",
    "            for track in result:\n",
    "                features.loc[track.name] = track\n",
    "\n",
    "#             # Reindex tracks with filenames (Do not use this if you later want to annotate track files with predicted genres)\n",
    "#             features = features.rename(index=paths_to_tracks)\n",
    "\n",
    "            # Remove dataframe rows containing NaN or Inf values\n",
    "            tmp_len = len(features)\n",
    "            features = features.replace(['-inf', 'inf', 'nan'], np.nan)\n",
    "            features = features.replace([np.inf, -np.inf], np.nan)\n",
    "            features = features.dropna()\n",
    "\n",
    "            print_log(\"Removed \" + str(tmp_len - len(features)) + \" corrupted tracks.\")\n",
    "            print_log(\"Final track count is: \" + str(len(features)) + \" tracks.\\n\\n\\n\")\n",
    "\n",
    "            # Drop unnecessary first level of multi-index created by Essentia extractor \n",
    "            if library_name == 'essentia':\n",
    "                features.columns = features.columns.droplevel()\n",
    "                \n",
    "            # Sort indices of a dataframe for more efficient slicing and save dataframe to .csv file\n",
    "            features = features.sort_index(axis=0)\n",
    "            features = features.sort_index(axis=1)\n",
    "            features.to_csv('../metadata/features/features_{}_{}.csv'.format(dataset_name, library_name))\n",
    "            \n",
    "    print_log(\"Feature extraction for all selected datasets and extraction libraries finished in ~\\033[1m{}\\033[0m.\".format(str(timedelta(seconds=(time.time() - t_start))).split(\".\")[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
